{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "Based on [DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow) by [Taehoon Kim](https://github.com/carpedm20) on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, time\n",
    "from glob import glob\n",
    "\n",
    "from ops import batch_norm, linear, conv2d, deconv2d, lrelu\n",
    "from image_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_crop = True\n",
    "batch_size = 64\n",
    "image_size = 108\n",
    "sample_size = 64\n",
    "image_shape = [64, 64, 3]\n",
    "\n",
    "z_dim = 100\n",
    "\n",
    "gf_dim = 64\n",
    "df_dim = 64\n",
    "\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "dataset = \"celebA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_bn1 = batch_norm(name='d_bn1')\n",
    "d_bn2 = batch_norm(name='d_bn2')\n",
    "d_bn3 = batch_norm(name='d_bn3')\n",
    "\n",
    "g_bn0 = batch_norm(name='g_bn0')\n",
    "g_bn1 = batch_norm(name='g_bn1')\n",
    "g_bn2 = batch_norm(name='g_bn2')\n",
    "g_bn3 = batch_norm(name='g_bn3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(image, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    h0 = lrelu(conv2d(image, df_dim, name='d_h0_conv'))\n",
    "    h1 = lrelu(d_bn1(conv2d(h0, df_dim*2, name='d_h1_conv')))\n",
    "    h2 = lrelu(d_bn2(conv2d(h1, df_dim*4, name='d_h2_conv')))\n",
    "    h3 = lrelu(d_bn3(conv2d(h2, df_dim*8, name='d_h3_conv')))\n",
    "    h4 = linear(tf.reshape(h3, [batch_size, -1]), 1, 'd_h3_lin')\n",
    "\n",
    "    return tf.nn.sigmoid(h4), h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    z_ = linear(z, gf_dim*8*4*4, 'g_h0_lin')\n",
    "\n",
    "    h0 = tf.nn.relu(g_bn0(tf.reshape(z_, [-1, 4, 4, gf_dim * 8])))\n",
    "    h1 = tf.nn.relu(g_bn1(deconv2d(h0, [batch_size, 8, 8, gf_dim*4], name='g_h1')))\n",
    "    h2 = tf.nn.relu(g_bn2(deconv2d(h1, [batch_size, 16, 16, gf_dim*2], name='g_h2')))\n",
    "    h3 = tf.nn.relu(g_bn3(deconv2d(h2, [batch_size, 32, 32, gf_dim*1], name='g_h3')))\n",
    "    h4 = deconv2d(h3, [batch_size, 64, 64, 3], name='g_h4')\n",
    "\n",
    "    return tf.nn.tanh(h4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = tf.placeholder(tf.float32, [batch_size] + image_shape, name='real_images')\n",
    "sample_images= tf.placeholder(tf.float32, [sample_size] + image_shape, name='sample_images')\n",
    "z = tf.placeholder(tf.float32, [None, z_dim], name='z')\n",
    "\n",
    "G = generator(z)\n",
    "D, D_logits = discriminator(images)\n",
    "D_, D_logits_ = discriminator(G, reuse=True)\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(D_logits, tf.ones_like(D)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(D_logits_, tf.zeros_like(D_)))\n",
    "d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(D_logits_, tf.ones_like(D_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "t_vars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "g_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "\n",
    "d_optim = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "g_optim = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [   0/3165] time: 2.5296, d_loss: 7.06200266, g_loss: 0.00102675\n",
      "Epoch: [ 0] [   1/3165] time: 3.0092, d_loss: 6.57333899, g_loss: 0.00187810\n",
      "Epoch: [ 0] [   2/3165] time: 3.4602, d_loss: 6.86497688, g_loss: 0.00281267\n",
      "Epoch: [ 0] [   3/3165] time: 3.9383, d_loss: 6.32483959, g_loss: 0.00638838\n",
      "Epoch: [ 0] [   4/3165] time: 4.3416, d_loss: 5.30031204, g_loss: 0.01770524\n",
      "Epoch: [ 0] [   5/3165] time: 4.7401, d_loss: 5.52699995, g_loss: 0.01167926\n",
      "Epoch: [ 0] [   6/3165] time: 5.1402, d_loss: 4.79769611, g_loss: 0.03223653\n",
      "Epoch: [ 0] [   7/3165] time: 5.5583, d_loss: 4.07475805, g_loss: 0.08372520\n",
      "Epoch: [ 0] [   8/3165] time: 5.9581, d_loss: 6.05643654, g_loss: 0.00666530\n",
      "Epoch: [ 0] [   9/3165] time: 6.3903, d_loss: 1.55849218, g_loss: 1.51691008\n",
      "Epoch: [ 0] [  10/3165] time: 6.7889, d_loss: 7.19772291, g_loss: 0.00154386\n",
      "Epoch: [ 0] [  11/3165] time: 7.1959, d_loss: 1.18330407, g_loss: 3.40889025\n",
      "Epoch: [ 0] [  12/3165] time: 7.5934, d_loss: 6.04397964, g_loss: 0.00730187\n",
      "Epoch: [ 0] [  13/3165] time: 8.0528, d_loss: 1.56349289, g_loss: 3.80764389\n",
      "Epoch: [ 0] [  14/3165] time: 8.4653, d_loss: 6.20572424, g_loss: 0.00974118\n",
      "Epoch: [ 0] [  15/3165] time: 8.8731, d_loss: 1.60061610, g_loss: 6.25353575\n",
      "Epoch: [ 0] [  16/3165] time: 9.2954, d_loss: 4.38403511, g_loss: 0.05119168\n",
      "Epoch: [ 0] [  17/3165] time: 9.6971, d_loss: 0.94983268, g_loss: 4.35259771\n",
      "Epoch: [ 0] [  18/3165] time: 10.1150, d_loss: 7.07916403, g_loss: 0.00288836\n",
      "Epoch: [ 0] [  19/3165] time: 10.5148, d_loss: 1.58276033, g_loss: 8.82818985\n",
      "Epoch: [ 0] [  20/3165] time: 10.9619, d_loss: 2.09212661, g_loss: 0.57928878\n",
      "Epoch: [ 0] [  21/3165] time: 11.3767, d_loss: 5.53284407, g_loss: 0.01208475\n",
      "Epoch: [ 0] [  22/3165] time: 11.7714, d_loss: 2.82484078, g_loss: 10.95905590\n",
      "Epoch: [ 0] [  23/3165] time: 12.1963, d_loss: 1.03845811, g_loss: 0.99695230\n",
      "Epoch: [ 0] [  24/3165] time: 12.5801, d_loss: 7.32857752, g_loss: 0.00191926\n",
      "Epoch: [ 0] [  25/3165] time: 12.9673, d_loss: 1.61386216, g_loss: 8.87827015\n",
      "Epoch: [ 0] [  26/3165] time: 13.3628, d_loss: 1.29308689, g_loss: 1.44075513\n",
      "Epoch: [ 0] [  27/3165] time: 13.8250, d_loss: 6.07866096, g_loss: 0.00495645\n",
      "Epoch: [ 0] [  28/3165] time: 14.2258, d_loss: 5.19211483, g_loss: 10.54669952\n",
      "Epoch: [ 0] [  29/3165] time: 14.6110, d_loss: 4.23316097, g_loss: 0.04156583\n",
      "Epoch: [ 0] [  30/3165] time: 15.0401, d_loss: 2.05570054, g_loss: 3.13413668\n",
      "Epoch: [ 0] [  31/3165] time: 15.4544, d_loss: 5.87731218, g_loss: 0.00970116\n",
      "Epoch: [ 0] [  32/3165] time: 15.8415, d_loss: 2.84502983, g_loss: 5.77974463\n",
      "Epoch: [ 0] [  33/3165] time: 16.2962, d_loss: 3.57127523, g_loss: 0.09095675\n",
      "Epoch: [ 0] [  34/3165] time: 16.6888, d_loss: 2.33114171, g_loss: 3.51142931\n",
      "Epoch: [ 0] [  35/3165] time: 17.0993, d_loss: 6.59928751, g_loss: 0.00362136\n",
      "Epoch: [ 0] [  36/3165] time: 17.4925, d_loss: 3.67150497, g_loss: 0.84496319\n",
      "Epoch: [ 0] [  37/3165] time: 17.8873, d_loss: 5.77075672, g_loss: 0.10525142\n",
      "Epoch: [ 0] [  38/3165] time: 18.2838, d_loss: 4.67799282, g_loss: 7.83133650\n",
      "Epoch: [ 0] [  39/3165] time: 18.6760, d_loss: 3.07290244, g_loss: 0.14161773\n",
      "Epoch: [ 0] [  40/3165] time: 19.0743, d_loss: 1.58605683, g_loss: 2.64604998\n",
      "Epoch: [ 0] [  41/3165] time: 19.4622, d_loss: 7.01664495, g_loss: 0.00434551\n",
      "Epoch: [ 0] [  42/3165] time: 19.8685, d_loss: 2.45109129, g_loss: 3.62819481\n",
      "Epoch: [ 0] [  43/3165] time: 20.2559, d_loss: 4.06443834, g_loss: 0.12431633\n",
      "Epoch: [ 0] [  44/3165] time: 20.6488, d_loss: 2.16582394, g_loss: 2.77465057\n",
      "Epoch: [ 0] [  45/3165] time: 21.0316, d_loss: 5.41831779, g_loss: 0.03741806\n",
      "Epoch: [ 0] [  46/3165] time: 21.4160, d_loss: 2.89296198, g_loss: 2.48699665\n",
      "Epoch: [ 0] [  47/3165] time: 21.8322, d_loss: 6.62881851, g_loss: 0.01504883\n",
      "Epoch: [ 0] [  48/3165] time: 22.2164, d_loss: 2.90366793, g_loss: 3.06390667\n",
      "Epoch: [ 0] [  49/3165] time: 22.9556, d_loss: 4.32242298, g_loss: 0.05088216\n",
      "Epoch: [ 0] [  50/3165] time: 23.3810, d_loss: 3.03842735, g_loss: 2.43144941\n",
      "Epoch: [ 0] [  51/3165] time: 23.7687, d_loss: 4.17205191, g_loss: 0.09440128\n",
      "Epoch: [ 0] [  52/3165] time: 24.1558, d_loss: 2.79647994, g_loss: 2.13868380\n",
      "Epoch: [ 0] [  53/3165] time: 24.5594, d_loss: 2.98986864, g_loss: 0.51584476\n",
      "Epoch: [ 0] [  54/3165] time: 24.9416, d_loss: 2.77609015, g_loss: 0.55928391\n",
      "Epoch: [ 0] [  55/3165] time: 25.3720, d_loss: 2.34590054, g_loss: 1.00896406\n",
      "Epoch: [ 0] [  56/3165] time: 25.7549, d_loss: 2.27543926, g_loss: 0.45167270\n",
      "Epoch: [ 0] [  57/3165] time: 26.1465, d_loss: 1.84199882, g_loss: 0.46689025\n",
      "Epoch: [ 0] [  58/3165] time: 26.6364, d_loss: 1.59683502, g_loss: 0.89945590\n",
      "Epoch: [ 0] [  59/3165] time: 27.0194, d_loss: 2.26506567, g_loss: 0.41817138\n",
      "Epoch: [ 0] [  60/3165] time: 27.4024, d_loss: 2.71604371, g_loss: 0.40388754\n",
      "Epoch: [ 0] [  61/3165] time: 27.7856, d_loss: 2.64483595, g_loss: 0.55775625\n",
      "Epoch: [ 0] [  62/3165] time: 28.2566, d_loss: 2.74471951, g_loss: 0.30213872\n",
      "Epoch: [ 0] [  63/3165] time: 28.6944, d_loss: 2.09385061, g_loss: 0.58821636\n",
      "Epoch: [ 0] [  64/3165] time: 29.0831, d_loss: 2.12923217, g_loss: 0.44582230\n",
      "Epoch: [ 0] [  65/3165] time: 29.4805, d_loss: 2.36591291, g_loss: 0.39589599\n",
      "Epoch: [ 0] [  66/3165] time: 29.8647, d_loss: 2.47723174, g_loss: 0.41777819\n",
      "Epoch: [ 0] [  67/3165] time: 30.2514, d_loss: 1.92431736, g_loss: 0.59370983\n",
      "Epoch: [ 0] [  68/3165] time: 30.6372, d_loss: 2.20384645, g_loss: 0.33367664\n",
      "Epoch: [ 0] [  69/3165] time: 31.0248, d_loss: 2.59513044, g_loss: 0.40497622\n",
      "Epoch: [ 0] [  70/3165] time: 31.4077, d_loss: 2.86984825, g_loss: 0.28937536\n",
      "Epoch: [ 0] [  71/3165] time: 31.8384, d_loss: 2.04980087, g_loss: 0.92830431\n",
      "Epoch: [ 0] [  72/3165] time: 32.2224, d_loss: 2.18088388, g_loss: 0.57353103\n",
      "Epoch: [ 0] [  73/3165] time: 32.6570, d_loss: 1.80137312, g_loss: 0.47830573\n",
      "Epoch: [ 0] [  74/3165] time: 33.0403, d_loss: 1.73579574, g_loss: 2.54174733\n",
      "Epoch: [ 0] [  75/3165] time: 33.4253, d_loss: 2.01490927, g_loss: 0.47891641\n",
      "Epoch: [ 0] [  76/3165] time: 33.8115, d_loss: 1.64228237, g_loss: 0.67821848\n",
      "Epoch: [ 0] [  77/3165] time: 34.2008, d_loss: 1.48278630, g_loss: 1.26982260\n",
      "Epoch: [ 0] [  78/3165] time: 34.6020, d_loss: 2.66310239, g_loss: 0.27133375\n",
      "Epoch: [ 0] [  79/3165] time: 34.9900, d_loss: 3.13301373, g_loss: 0.30836710\n",
      "Epoch: [ 0] [  80/3165] time: 35.3752, d_loss: 3.64281702, g_loss: 0.36054486\n",
      "Epoch: [ 0] [  81/3165] time: 35.7602, d_loss: 2.80661440, g_loss: 0.70180452\n",
      "Epoch: [ 0] [  82/3165] time: 36.1486, d_loss: 1.74637949, g_loss: 0.71396732\n",
      "Epoch: [ 0] [  83/3165] time: 36.5348, d_loss: 1.89660835, g_loss: 0.65135908\n",
      "Epoch: [ 0] [  84/3165] time: 36.9189, d_loss: 1.89276409, g_loss: 0.82515490\n",
      "Epoch: [ 0] [  85/3165] time: 37.3321, d_loss: 1.72403240, g_loss: 0.85286355\n",
      "Epoch: [ 0] [  86/3165] time: 37.7186, d_loss: 1.48277807, g_loss: 0.86583543\n",
      "Epoch: [ 0] [  87/3165] time: 38.1068, d_loss: 1.25504827, g_loss: 0.68299246\n",
      "Epoch: [ 0] [  88/3165] time: 38.4976, d_loss: 1.26580048, g_loss: 1.22147250\n",
      "Epoch: [ 0] [  89/3165] time: 38.8816, d_loss: 1.40327024, g_loss: 0.55169189\n",
      "Epoch: [ 0] [  90/3165] time: 39.2729, d_loss: 1.38421190, g_loss: 0.75950068\n",
      "Epoch: [ 0] [  91/3165] time: 39.6656, d_loss: 1.76268494, g_loss: 0.58440667\n",
      "Epoch: [ 0] [  92/3165] time: 40.0587, d_loss: 1.61160505, g_loss: 1.12029982\n",
      "Epoch: [ 0] [  93/3165] time: 40.4467, d_loss: 1.89115894, g_loss: 0.49716455\n",
      "Epoch: [ 0] [  94/3165] time: 40.8329, d_loss: 1.75014877, g_loss: 0.73918784\n",
      "Epoch: [ 0] [  95/3165] time: 41.2313, d_loss: 1.82948637, g_loss: 0.70957118\n",
      "Epoch: [ 0] [  96/3165] time: 41.6167, d_loss: 1.86623955, g_loss: 0.65268165\n",
      "Epoch: [ 0] [  97/3165] time: 42.0275, d_loss: 1.72682381, g_loss: 0.63472688\n",
      "Epoch: [ 0] [  98/3165] time: 42.4130, d_loss: 1.55111670, g_loss: 0.70333529\n",
      "Epoch: [ 0] [  99/3165] time: 42.7986, d_loss: 1.45731354, g_loss: 0.91664642\n",
      "[Sample] d_loss: 1.18682432, g_loss: 1.22035003\n",
      "Epoch: [ 0] [ 100/3165] time: 43.4699, d_loss: 1.21984613, g_loss: 0.74403822\n",
      "Epoch: [ 0] [ 101/3165] time: 43.8912, d_loss: 1.34910178, g_loss: 0.96965343\n",
      "Epoch: [ 0] [ 102/3165] time: 44.2746, d_loss: 1.33566356, g_loss: 0.78339016\n",
      "Epoch: [ 0] [ 103/3165] time: 44.6608, d_loss: 1.31995559, g_loss: 0.90762901\n",
      "Epoch: [ 0] [ 104/3165] time: 45.0436, d_loss: 1.23505974, g_loss: 0.95410204\n",
      "Epoch: [ 0] [ 105/3165] time: 45.4283, d_loss: 1.30385733, g_loss: 0.57635230\n",
      "Epoch: [ 0] [ 106/3165] time: 45.8120, d_loss: 1.75576329, g_loss: 0.83434510\n",
      "Epoch: [ 0] [ 107/3165] time: 46.1968, d_loss: 1.68001652, g_loss: 0.46879065\n",
      "Epoch: [ 0] [ 108/3165] time: 46.6162, d_loss: 1.45672274, g_loss: 0.89710826\n",
      "Epoch: [ 0] [ 109/3165] time: 47.0030, d_loss: 1.69468033, g_loss: 0.47638768\n",
      "Epoch: [ 0] [ 110/3165] time: 47.4084, d_loss: 1.65525436, g_loss: 0.65949142\n",
      "Epoch: [ 0] [ 111/3165] time: 47.7940, d_loss: 1.36675858, g_loss: 0.87935781\n",
      "Epoch: [ 0] [ 112/3165] time: 48.1787, d_loss: 1.41483295, g_loss: 0.64717633\n",
      "Epoch: [ 0] [ 113/3165] time: 48.6170, d_loss: 1.29231310, g_loss: 0.87226689\n",
      "Epoch: [ 0] [ 114/3165] time: 49.0007, d_loss: 1.34820342, g_loss: 0.62970811\n",
      "Epoch: [ 0] [ 115/3165] time: 49.3859, d_loss: 1.11895561, g_loss: 0.95513445\n",
      "Epoch: [ 0] [ 116/3165] time: 49.7835, d_loss: 1.64553869, g_loss: 0.42587268\n",
      "Epoch: [ 0] [ 117/3165] time: 50.1699, d_loss: 1.24930787, g_loss: 1.32842922\n",
      "Epoch: [ 0] [ 118/3165] time: 50.5547, d_loss: 1.30445123, g_loss: 0.59551060\n",
      "Epoch: [ 0] [ 119/3165] time: 50.9408, d_loss: 1.19938135, g_loss: 1.35115445\n",
      "Epoch: [ 0] [ 120/3165] time: 51.3254, d_loss: 1.43051481, g_loss: 0.47678727\n",
      "Epoch: [ 0] [ 121/3165] time: 51.7111, d_loss: 1.17649877, g_loss: 1.14880919\n",
      "Epoch: [ 0] [ 122/3165] time: 52.0950, d_loss: 1.48265707, g_loss: 0.64026439\n",
      "Epoch: [ 0] [ 123/3165] time: 52.4824, d_loss: 1.72491789, g_loss: 0.45937097\n",
      "Epoch: [ 0] [ 124/3165] time: 52.9338, d_loss: 1.44834137, g_loss: 0.89653838\n",
      "Epoch: [ 0] [ 125/3165] time: 53.3197, d_loss: 1.23430216, g_loss: 1.09495854\n",
      "Epoch: [ 0] [ 126/3165] time: 53.7344, d_loss: 1.61550403, g_loss: 0.54643786\n",
      "Epoch: [ 0] [ 127/3165] time: 54.1200, d_loss: 1.40679669, g_loss: 0.61980343\n",
      "Epoch: [ 0] [ 128/3165] time: 54.5042, d_loss: 1.52241206, g_loss: 0.73059225\n",
      "Epoch: [ 0] [ 129/3165] time: 54.8904, d_loss: 1.48111022, g_loss: 0.55457532\n",
      "Epoch: [ 0] [ 130/3165] time: 55.2748, d_loss: 1.64130688, g_loss: 1.09827590\n",
      "Epoch: [ 0] [ 131/3165] time: 55.6611, d_loss: 2.00942993, g_loss: 0.46892428\n",
      "Epoch: [ 0] [ 132/3165] time: 56.0474, d_loss: 1.49312413, g_loss: 1.24692559\n",
      "Epoch: [ 0] [ 133/3165] time: 56.4336, d_loss: 1.59427845, g_loss: 0.74286252\n",
      "Epoch: [ 0] [ 134/3165] time: 56.8201, d_loss: 1.79174793, g_loss: 0.90699041\n",
      "Epoch: [ 0] [ 135/3165] time: 57.2065, d_loss: 2.20564985, g_loss: 0.33505255\n",
      "Epoch: [ 0] [ 136/3165] time: 57.5900, d_loss: 1.47428274, g_loss: 1.56627572\n",
      "Epoch: [ 0] [ 137/3165] time: 57.9764, d_loss: 1.93497491, g_loss: 0.40292209\n",
      "Epoch: [ 0] [ 138/3165] time: 58.3735, d_loss: 1.75461030, g_loss: 0.66397536\n",
      "Epoch: [ 0] [ 139/3165] time: 58.7605, d_loss: 2.19979811, g_loss: 0.49769425\n",
      "Epoch: [ 0] [ 140/3165] time: 59.1461, d_loss: 2.17588449, g_loss: 0.83020353\n",
      "Epoch: [ 0] [ 141/3165] time: 59.5331, d_loss: 2.13738728, g_loss: 0.52395457\n",
      "Epoch: [ 0] [ 142/3165] time: 59.9359, d_loss: 1.46542597, g_loss: 0.91223454\n",
      "Epoch: [ 0] [ 143/3165] time: 60.3222, d_loss: 1.38455236, g_loss: 0.82203907\n",
      "Epoch: [ 0] [ 144/3165] time: 60.7130, d_loss: 1.46695971, g_loss: 0.81696445\n",
      "Epoch: [ 0] [ 145/3165] time: 61.1079, d_loss: 1.40285397, g_loss: 0.70132732\n",
      "Epoch: [ 0] [ 146/3165] time: 61.5055, d_loss: 1.48278439, g_loss: 1.13846076\n",
      "Epoch: [ 0] [ 147/3165] time: 61.9138, d_loss: 1.43218541, g_loss: 0.55011737\n",
      "Epoch: [ 0] [ 148/3165] time: 62.3239, d_loss: 1.35107541, g_loss: 0.87354684\n",
      "Epoch: [ 0] [ 149/3165] time: 62.7423, d_loss: 1.28956711, g_loss: 0.84962082\n",
      "Epoch: [ 0] [ 150/3165] time: 63.1618, d_loss: 1.23995280, g_loss: 0.87429082\n",
      "Epoch: [ 0] [ 151/3165] time: 63.5890, d_loss: 1.41213441, g_loss: 0.51420379\n",
      "Epoch: [ 0] [ 152/3165] time: 64.0039, d_loss: 1.09735370, g_loss: 1.38582587\n",
      "Epoch: [ 0] [ 153/3165] time: 64.4225, d_loss: 1.53966784, g_loss: 0.43750921\n",
      "Epoch: [ 0] [ 154/3165] time: 64.8377, d_loss: 1.47166061, g_loss: 1.23088551\n",
      "Epoch: [ 0] [ 155/3165] time: 65.2549, d_loss: 1.70362210, g_loss: 0.41275188\n",
      "Epoch: [ 0] [ 156/3165] time: 65.6707, d_loss: 1.27043962, g_loss: 1.85667539\n",
      "Epoch: [ 0] [ 157/3165] time: 66.0887, d_loss: 1.39070165, g_loss: 0.51562077\n",
      "Epoch: [ 0] [ 158/3165] time: 66.5048, d_loss: 1.20260501, g_loss: 0.74568892\n",
      "Epoch: [ 0] [ 159/3165] time: 66.9578, d_loss: 1.98528671, g_loss: 0.78376788\n",
      "Epoch: [ 0] [ 160/3165] time: 67.3739, d_loss: 1.36316192, g_loss: 0.71095383\n",
      "Epoch: [ 0] [ 161/3165] time: 67.7946, d_loss: 1.15679002, g_loss: 1.24876380\n",
      "Epoch: [ 0] [ 162/3165] time: 68.2098, d_loss: 2.00010157, g_loss: 0.30637893\n",
      "Epoch: [ 0] [ 163/3165] time: 68.6836, d_loss: 1.40232325, g_loss: 1.11136973\n",
      "Epoch: [ 0] [ 164/3165] time: 69.0960, d_loss: 2.05175686, g_loss: 0.32858160\n",
      "Epoch: [ 0] [ 165/3165] time: 69.5131, d_loss: 1.48629045, g_loss: 1.28308034\n",
      "Epoch: [ 0] [ 166/3165] time: 69.9297, d_loss: 2.64889884, g_loss: 0.24072570\n",
      "Epoch: [ 0] [ 167/3165] time: 70.3471, d_loss: 1.74164557, g_loss: 1.97951901\n",
      "Epoch: [ 0] [ 168/3165] time: 70.7621, d_loss: 1.62808371, g_loss: 0.43557256\n",
      "Epoch: [ 0] [ 169/3165] time: 71.1809, d_loss: 1.55775642, g_loss: 0.84294444\n",
      "Epoch: [ 0] [ 170/3165] time: 71.6213, d_loss: 1.61551321, g_loss: 0.62792337\n",
      "Epoch: [ 0] [ 171/3165] time: 72.0375, d_loss: 2.54480600, g_loss: 0.24706110\n",
      "Epoch: [ 0] [ 172/3165] time: 72.4779, d_loss: 2.51582670, g_loss: 0.77584529\n",
      "Epoch: [ 0] [ 173/3165] time: 72.8899, d_loss: 2.37659693, g_loss: 0.22624078\n",
      "Epoch: [ 0] [ 174/3165] time: 73.3398, d_loss: 1.95000315, g_loss: 0.84087437\n",
      "Epoch: [ 0] [ 175/3165] time: 73.7470, d_loss: 1.66577625, g_loss: 0.56309283\n",
      "Epoch: [ 0] [ 176/3165] time: 74.1518, d_loss: 1.49196982, g_loss: 0.80550671\n",
      "Epoch: [ 0] [ 177/3165] time: 74.5544, d_loss: 1.81143403, g_loss: 0.46414483\n",
      "Epoch: [ 0] [ 178/3165] time: 74.9548, d_loss: 1.87627172, g_loss: 0.66488528\n",
      "Epoch: [ 0] [ 179/3165] time: 75.3564, d_loss: 1.63713264, g_loss: 0.71180868\n",
      "Epoch: [ 0] [ 180/3165] time: 75.7568, d_loss: 1.78018904, g_loss: 0.38997105\n",
      "Epoch: [ 0] [ 181/3165] time: 76.1608, d_loss: 1.48526835, g_loss: 1.08254671\n",
      "Epoch: [ 0] [ 182/3165] time: 76.5621, d_loss: 1.88301432, g_loss: 0.43404850\n",
      "Epoch: [ 0] [ 183/3165] time: 76.9663, d_loss: 1.96266031, g_loss: 0.55422717\n",
      "Epoch: [ 0] [ 184/3165] time: 77.3699, d_loss: 1.52621639, g_loss: 0.81781113\n",
      "Epoch: [ 0] [ 185/3165] time: 77.7984, d_loss: 1.39497209, g_loss: 0.77926171\n",
      "Epoch: [ 0] [ 186/3165] time: 78.2007, d_loss: 1.45200419, g_loss: 0.52655381\n",
      "Epoch: [ 0] [ 187/3165] time: 78.6043, d_loss: 1.53755927, g_loss: 0.87838519\n",
      "Epoch: [ 0] [ 188/3165] time: 79.0076, d_loss: 1.69423330, g_loss: 0.47687018\n",
      "Epoch: [ 0] [ 189/3165] time: 79.4125, d_loss: 1.61633587, g_loss: 0.74612868\n",
      "Epoch: [ 0] [ 190/3165] time: 79.8158, d_loss: 1.59545112, g_loss: 0.64721841\n",
      "Epoch: [ 0] [ 191/3165] time: 80.2224, d_loss: 1.37885582, g_loss: 0.74362123\n",
      "Epoch: [ 0] [ 192/3165] time: 80.6273, d_loss: 1.37806582, g_loss: 0.67464536\n",
      "Epoch: [ 0] [ 193/3165] time: 81.0355, d_loss: 1.25137496, g_loss: 0.81429470\n",
      "Epoch: [ 0] [ 194/3165] time: 81.4454, d_loss: 1.10391915, g_loss: 1.17296243\n",
      "Epoch: [ 0] [ 195/3165] time: 81.8563, d_loss: 1.77656686, g_loss: 0.27825963\n",
      "Epoch: [ 0] [ 196/3165] time: 82.2679, d_loss: 2.04240131, g_loss: 2.67507195\n",
      "Epoch: [ 0] [ 197/3165] time: 82.6789, d_loss: 1.92869043, g_loss: 0.23386472\n",
      "Epoch: [ 0] [ 198/3165] time: 83.0888, d_loss: 1.09463239, g_loss: 1.11608505\n",
      "Epoch: [ 0] [ 199/3165] time: 83.4994, d_loss: 1.16077864, g_loss: 0.88273603\n",
      "[Sample] d_loss: 1.09562850, g_loss: 1.13609505\n",
      "Epoch: [ 0] [ 200/3165] time: 83.9988, d_loss: 1.73808086, g_loss: 0.39669982\n",
      "Epoch: [ 0] [ 201/3165] time: 84.4066, d_loss: 1.77501345, g_loss: 1.20068550\n",
      "Epoch: [ 0] [ 202/3165] time: 84.8148, d_loss: 2.09259963, g_loss: 0.22931540\n",
      "Epoch: [ 0] [ 203/3165] time: 85.2195, d_loss: 2.05366993, g_loss: 2.07735872\n",
      "Epoch: [ 0] [ 204/3165] time: 85.6213, d_loss: 1.96067882, g_loss: 0.26608342\n",
      "Epoch: [ 0] [ 205/3165] time: 86.0220, d_loss: 1.51660872, g_loss: 0.97613245\n",
      "Epoch: [ 0] [ 206/3165] time: 86.4223, d_loss: 1.74620819, g_loss: 0.53822505\n",
      "Epoch: [ 0] [ 207/3165] time: 86.8229, d_loss: 1.36186051, g_loss: 0.95327598\n",
      "Epoch: [ 0] [ 208/3165] time: 87.2223, d_loss: 1.76705885, g_loss: 0.38751000\n",
      "Epoch: [ 0] [ 209/3165] time: 87.6214, d_loss: 1.42164814, g_loss: 0.76403272\n",
      "Epoch: [ 0] [ 210/3165] time: 88.0213, d_loss: 1.46897292, g_loss: 0.78577971\n",
      "Epoch: [ 0] [ 211/3165] time: 88.4225, d_loss: 1.30017400, g_loss: 0.75433123\n",
      "Epoch: [ 0] [ 212/3165] time: 88.8259, d_loss: 1.36100292, g_loss: 1.02722633\n",
      "Epoch: [ 0] [ 213/3165] time: 89.2309, d_loss: 1.46775699, g_loss: 0.50233454\n",
      "Epoch: [ 0] [ 214/3165] time: 89.6636, d_loss: 1.10632133, g_loss: 1.11704087\n",
      "Epoch: [ 0] [ 215/3165] time: 90.0727, d_loss: 1.47470057, g_loss: 0.64427257\n",
      "Epoch: [ 0] [ 216/3165] time: 90.4800, d_loss: 1.50698221, g_loss: 0.68821633\n",
      "Epoch: [ 0] [ 217/3165] time: 90.8888, d_loss: 1.55371606, g_loss: 0.60600793\n",
      "Epoch: [ 0] [ 218/3165] time: 91.3006, d_loss: 1.63830280, g_loss: 0.68406266\n",
      "Epoch: [ 0] [ 219/3165] time: 91.7108, d_loss: 1.32328486, g_loss: 0.91770017\n",
      "Epoch: [ 0] [ 220/3165] time: 92.1215, d_loss: 1.24486947, g_loss: 0.62510633\n",
      "Epoch: [ 0] [ 221/3165] time: 92.5325, d_loss: 1.35941017, g_loss: 0.85086858\n",
      "Epoch: [ 0] [ 222/3165] time: 92.9397, d_loss: 1.49799943, g_loss: 0.62364280\n",
      "Epoch: [ 0] [ 223/3165] time: 93.3461, d_loss: 1.69943118, g_loss: 0.42523509\n",
      "Epoch: [ 0] [ 224/3165] time: 93.8018, d_loss: 2.16330314, g_loss: 1.52879703\n",
      "Epoch: [ 0] [ 225/3165] time: 94.2068, d_loss: 2.61533856, g_loss: 0.13434970\n",
      "Epoch: [ 0] [ 226/3165] time: 94.6215, d_loss: 1.99690175, g_loss: 1.22358370\n",
      "Epoch: [ 0] [ 227/3165] time: 95.0217, d_loss: 2.10247469, g_loss: 0.27994156\n",
      "Epoch: [ 0] [ 228/3165] time: 95.4223, d_loss: 1.72436666, g_loss: 0.63415664\n",
      "Epoch: [ 0] [ 229/3165] time: 95.8233, d_loss: 1.72226882, g_loss: 0.40053779\n",
      "Epoch: [ 0] [ 230/3165] time: 96.2251, d_loss: 1.55482256, g_loss: 0.65107071\n",
      "Epoch: [ 0] [ 231/3165] time: 96.6265, d_loss: 1.58979547, g_loss: 0.68735468\n",
      "Epoch: [ 0] [ 232/3165] time: 97.0292, d_loss: 2.02539277, g_loss: 0.66549516\n",
      "Epoch: [ 0] [ 233/3165] time: 97.4321, d_loss: 2.03202939, g_loss: 0.30865559\n",
      "Epoch: [ 0] [ 234/3165] time: 97.8386, d_loss: 1.81002069, g_loss: 0.92465538\n",
      "Epoch: [ 0] [ 235/3165] time: 98.2463, d_loss: 1.60194290, g_loss: 0.44258374\n",
      "Epoch: [ 0] [ 236/3165] time: 98.6572, d_loss: 1.32823336, g_loss: 0.90796649\n",
      "Epoch: [ 0] [ 237/3165] time: 99.0668, d_loss: 1.64359403, g_loss: 0.45097169\n",
      "Epoch: [ 0] [ 238/3165] time: 99.4776, d_loss: 1.33951664, g_loss: 1.31478882\n",
      "Epoch: [ 0] [ 239/3165] time: 99.8878, d_loss: 1.40691304, g_loss: 0.55417722\n",
      "Epoch: [ 0] [ 240/3165] time: 100.2978, d_loss: 1.43580794, g_loss: 1.18481565\n",
      "Epoch: [ 0] [ 241/3165] time: 100.7091, d_loss: 1.58026206, g_loss: 0.52547860\n",
      "Epoch: [ 0] [ 242/3165] time: 101.1214, d_loss: 1.75651240, g_loss: 0.35626122\n",
      "Epoch: [ 0] [ 243/3165] time: 101.5341, d_loss: 2.15546608, g_loss: 1.10095990\n",
      "Epoch: [ 0] [ 244/3165] time: 101.9436, d_loss: 1.99816227, g_loss: 0.33157045\n",
      "Epoch: [ 0] [ 245/3165] time: 102.3541, d_loss: 1.63236904, g_loss: 1.08349872\n",
      "Epoch: [ 0] [ 246/3165] time: 102.7903, d_loss: 1.65050864, g_loss: 0.44267225\n",
      "Epoch: [ 0] [ 247/3165] time: 103.1979, d_loss: 1.54866552, g_loss: 0.66698074\n",
      "Epoch: [ 0] [ 248/3165] time: 103.6027, d_loss: 1.64996862, g_loss: 0.70348364\n",
      "Epoch: [ 0] [ 249/3165] time: 104.0070, d_loss: 1.76413131, g_loss: 0.51907170\n",
      "Epoch: [ 0] [ 250/3165] time: 104.4101, d_loss: 1.46945834, g_loss: 0.63375092\n",
      "Epoch: [ 0] [ 251/3165] time: 104.8140, d_loss: 1.70325398, g_loss: 0.62007213\n",
      "Epoch: [ 0] [ 252/3165] time: 105.2200, d_loss: 1.35267448, g_loss: 0.68517554\n",
      "Epoch: [ 0] [ 253/3165] time: 105.6292, d_loss: 1.69794321, g_loss: 0.50550699\n",
      "Epoch: [ 0] [ 254/3165] time: 106.0381, d_loss: 1.62633145, g_loss: 0.64950234\n",
      "Epoch: [ 0] [ 255/3165] time: 106.4444, d_loss: 1.43114436, g_loss: 0.56504571\n",
      "Epoch: [ 0] [ 256/3165] time: 106.8514, d_loss: 1.36981916, g_loss: 0.69091392\n",
      "Epoch: [ 0] [ 257/3165] time: 107.2605, d_loss: 1.28793025, g_loss: 0.83197385\n",
      "Epoch: [ 0] [ 258/3165] time: 107.6696, d_loss: 1.60158587, g_loss: 0.47395515\n",
      "Epoch: [ 0] [ 259/3165] time: 108.0801, d_loss: 1.37963390, g_loss: 1.07028377\n",
      "Epoch: [ 0] [ 260/3165] time: 108.4886, d_loss: 1.43523300, g_loss: 0.59097391\n",
      "Epoch: [ 0] [ 261/3165] time: 108.8971, d_loss: 1.50044298, g_loss: 0.55290139\n",
      "Epoch: [ 0] [ 262/3165] time: 109.3052, d_loss: 1.47021854, g_loss: 0.96920347\n",
      "Epoch: [ 0] [ 263/3165] time: 109.7133, d_loss: 1.72035503, g_loss: 0.42935234\n",
      "Epoch: [ 0] [ 264/3165] time: 110.1261, d_loss: 1.48144650, g_loss: 0.73106229\n",
      "Epoch: [ 0] [ 265/3165] time: 110.5397, d_loss: 1.76022518, g_loss: 0.56218851\n",
      "Epoch: [ 0] [ 266/3165] time: 110.9916, d_loss: 1.60346210, g_loss: 0.55820477\n",
      "Epoch: [ 0] [ 267/3165] time: 111.3986, d_loss: 1.86039424, g_loss: 0.40851712\n",
      "Epoch: [ 0] [ 268/3165] time: 111.8047, d_loss: 1.70525324, g_loss: 0.98105508\n",
      "Epoch: [ 0] [ 269/3165] time: 112.2074, d_loss: 1.80841851, g_loss: 0.27854395\n",
      "Epoch: [ 0] [ 270/3165] time: 112.6074, d_loss: 1.70134115, g_loss: 1.30899143\n",
      "Epoch: [ 0] [ 271/3165] time: 113.0080, d_loss: 1.78433537, g_loss: 0.32005328\n",
      "Epoch: [ 0] [ 272/3165] time: 113.4113, d_loss: 1.51405692, g_loss: 0.95131087\n",
      "Epoch: [ 0] [ 273/3165] time: 113.8236, d_loss: 1.89068508, g_loss: 0.31573913\n",
      "Epoch: [ 0] [ 274/3165] time: 114.2281, d_loss: 1.69407701, g_loss: 0.91531616\n",
      "Epoch: [ 0] [ 275/3165] time: 114.6331, d_loss: 1.88810539, g_loss: 0.39273289\n",
      "Epoch: [ 0] [ 276/3165] time: 115.0394, d_loss: 1.75445235, g_loss: 1.00159848\n",
      "Epoch: [ 0] [ 277/3165] time: 115.5069, d_loss: 1.85995007, g_loss: 0.32029989\n",
      "Epoch: [ 0] [ 278/3165] time: 115.9109, d_loss: 1.86422753, g_loss: 0.87341702\n",
      "Epoch: [ 0] [ 279/3165] time: 116.3140, d_loss: 2.00430918, g_loss: 0.36659110\n",
      "Epoch: [ 0] [ 280/3165] time: 116.7121, d_loss: 1.67672467, g_loss: 0.93621790\n",
      "Epoch: [ 0] [ 281/3165] time: 117.1123, d_loss: 1.73950589, g_loss: 0.38915223\n",
      "Epoch: [ 0] [ 282/3165] time: 117.5111, d_loss: 1.43126273, g_loss: 1.21778750\n",
      "Epoch: [ 0] [ 283/3165] time: 117.9113, d_loss: 1.84686732, g_loss: 0.32270080\n",
      "Epoch: [ 0] [ 284/3165] time: 118.3157, d_loss: 1.56692338, g_loss: 1.21320343\n"
     ]
    }
   ],
   "source": [
    "data = glob(os.path.join('data', dataset, '*.jpg'))\n",
    "\n",
    "d_optim = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "g_optim = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "sample_z = np.random.uniform(-1, 1, size=(sample_size , z_dim))\n",
    "sample_files = data[0:sample_size]\n",
    "sample = [get_image(sample_file, image_size, is_crop=is_crop) for sample_file in sample_files]\n",
    "sample_images = np.reshape(np.array(sample).astype(np.float32), [sample_size] + image_shape)\n",
    "\n",
    "counter = 1\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10):\n",
    "    data = glob(os.path.join('data', dataset, '*.jpg'))\n",
    "    np.random.shuffle(data)\n",
    "    batch_idxs = len(data)/batch_size\n",
    "\n",
    "    for idx in range(batch_idxs):\n",
    "        batch_files = data[idx*batch_size:(idx+1)*batch_size]\n",
    "        batch = [get_image(batch_file, image_size, is_crop=is_crop) for batch_file in batch_files]\n",
    "        batch_images = np.reshape(np.array(batch).astype(np.float32), [batch_size] + image_shape)\n",
    "\n",
    "        batch_z = np.random.uniform(-1, 1, [batch_size, z_dim]).astype(np.float32)\n",
    "\n",
    "        # Update D network\n",
    "        sess.run([d_optim], feed_dict={images: batch_images, z: batch_z})\n",
    "\n",
    "        # Update G network\n",
    "        sess.run([g_optim], feed_dict={z: batch_z})\n",
    "\n",
    "        # Run g_optim twice to make sure that d_loss does not go to zero (different from paper)\n",
    "        sess.run([g_optim], feed_dict={z: batch_z})\n",
    "\n",
    "        errD_fake = d_loss_fake.eval({z: batch_z}, session=sess)\n",
    "        errD_real = d_loss_real.eval({images: batch_images}, session=sess)\n",
    "        errG = g_loss.eval({z: batch_z}, session=sess)\n",
    "\n",
    "        counter += 1\n",
    "        print('Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f' \\\n",
    "            % (epoch, idx, batch_idxs, time.time() - start_time, errD_fake+errD_real, errG))\n",
    "\n",
    "        if np.mod(counter, 100) == 1:\n",
    "            samples, dl, gl = sess.run([G, d_loss, g_loss], feed_dict={z: sample_z, images: sample_images})\n",
    "            save_images(samples, [8, 8], './samples/train_%s_%s.png' % (epoch, idx))\n",
    "            print('[Sample] d_loss: %.8f, g_loss: %.8f' % (dl, gl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
